#!/usr/bin/env python3
# Weekly Data Gathering.py — fetch weekly Google Trends for tickers (US, 2023, Web Search).
# Writes: data/trends_csv_exports/<TICKER>.csv with columns: Week,<TICKER>,isPartial
# NOTE: retries=0 to avoid urllib3 v2 'method_whitelist' error inside pytrends.

from __future__ import annotations
from pathlib import Path
import time, random
import pandas as pd
from pytrends.request import TrendReq

# -------- Settings --------
TICKERS = [
    "AMC","GME","TSLA","NVDA","AAPL","NIO","PLTR",
    "RIVN","LCID","SOFI","META","BBBYQ","CVNA",
    "SPCE","NKLA"  # <-- swapped in for AMD, ROKU
]
YEAR = 2023
GEO = "US"      # United States
GPROP = ""      # Web Search
CATEGORY = 0    # All categories

OUTDIR = Path("data/trends_csv_exports")
OUTDIR.mkdir(parents=True, exist_ok=True)

# light pacing to reduce 429s
BETWEEN_TICKERS = (2.0, 4.0)  # seconds jitter
BATCH_SIZE      = 6
BATCH_PAUSE_S   = 25
HARD_429_SLEEP  = 60          # on 429, cool down ~60s

def fetch_one(pt: TrendReq, term: str) -> pd.DataFrame:
    """Return DataFrame like the site export: Week, <term>, isPartial (weekly for 2023/US/Web)."""
    timeframe = f"{YEAR}-01-01 {YEAR}-12-31"
    MAX_ATTEMPTS = 5
    for attempt in range(1, MAX_ATTEMPTS + 1):
        try:
            pt.build_payload([term], timeframe=timeframe, geo=GEO, gprop=GPROP, cat=CATEGORY)
            df = pt.interest_over_time()
            if df is None or df.empty or term not in df.columns:
                raise RuntimeError("Empty result or missing term column")
            return pd.DataFrame({
                "Week": df.index.date,
                term: df[term].astype(float).round(0).astype(int),
                "isPartial": df["isPartial"].astype(bool)
            })
        except Exception as e:
            msg = str(e).lower()
            # on 429, hard sleep ~60s; else short backoff
            pause = HARD_429_SLEEP if ("429" in msg or "too many" in msg or "rate" in msg) \
                    else min(6, 2 * attempt) + random.uniform(0, 0.5)
            print(f"[{term}] attempt {attempt} failed: {e} — sleeping {pause:.1f}s")
            time.sleep(pause)
    # all attempts failed → header-only frame
    return pd.DataFrame(columns=["Week", term, "isPartial"])

def main():
    print(f"Fetching weekly Google Trends for {len(TICKERS)} tickers (US, {YEAR}, Web Search)…\n")

    # KEY: retries=0 to avoid urllib3 v2 incompat in pytrends
    pt = TrendReq(hl="en-US", tz=0, timeout=(30, 60), retries=0, backoff_factor=0.0, requests_args={})

    for i, term in enumerate(TICKERS, start=1):
        path = OUTDIR / f"{term}.csv"
        df = fetch_one(pt, term)

        if df.empty:
            path.write_text(f"Week,{term},isPartial\n", encoding="utf-8")
            print(f"[{term}] FAILED — wrote header-only CSV")
        else:
            df.to_csv(path, index=False, encoding="utf-8")
            mx = int(df[term].max())
            has100 = 1 if mx == 100 else 0
            print(f"[{term}] wrote {len(df)} weeks → {path.name} (max={mx}, has_100={has100})")

        # anti-burst pacing
        time.sleep(random.uniform(*BETWEEN_TICKERS))
        if i % BATCH_SIZE == 0:
            print(f"— small batch pause ({BATCH_PAUSE_S}s) —")
            time.sleep(BATCH_PAUSE_S)

    print("\nDone. CSVs are in:", OUTDIR.resolve())

if __name__ == "__main__":
    main()
