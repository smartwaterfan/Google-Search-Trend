#!/usr/bin/env python3
# Peaks.py â€” read only the CSVs for the tickers below and list weeks with GST >= THRESHOLD
# Input:  data/trends_csv_exports/<TICKER>.csv  (Week,<TICKER>,isPartial)
# Output: output/gst_week_starts_2023_th80.csv

from __future__ import annotations
from pathlib import Path
import pandas as pd

# --- same tickers here (so AMD/ROKU are excluded) ---
TICKERS = [
    "AMC","GME","TSLA","NVDA","AAPL","NIO","PLTR",
    "RIVN","LCID","SOFI","META","BBBYQ","CVNA",
    "SPCE","NKLA"
]

YEAR = 2023
THRESHOLD = 80
CSV_DIR  = Path("data/trends_csv_exports")
OUTFILE  = Path(f"output/gst_week_starts_{YEAR}_th{THRESHOLD}.csv")

def _normalize_label(s: str) -> str:
    s = s.strip()
    s = s.split(":", 1)[0]
    s = s.split("(", 1)[0]
    return s.strip().lower()

def _pick_value_column(df: pd.DataFrame, term: str) -> str | None:
    cols = [c for c in df.columns if c.lower() not in {"week", "ispartial"}]
    for c in cols:
        if c.lower() == term.lower(): return c
    tgt = _normalize_label(term)
    for c in cols:
        if _normalize_label(c) == tgt: return c
    for c in cols:
        if tgt in _normalize_label(c): return c
    return cols[0] if cols else None

def read_one(csv_path: Path, ticker: str) -> pd.DataFrame:
    if not csv_path.exists():
        print(f"[{ticker}] missing CSV: {csv_path.name}")
        return pd.DataFrame()

    df = pd.read_csv(csv_path, encoding="utf-8-sig")
    if "Week" not in df.columns:
        print(f"[{ticker}] malformed CSV (no 'Week'): {csv_path.name}")
        return pd.DataFrame()

    val_col = _pick_value_column(df, ticker)
    if not val_col:
        print(f"[{ticker}] could not find value column in {csv_path.name}")
        return pd.DataFrame()

    vals = pd.to_numeric(df[val_col].astype(str).replace("<1","0"), errors="coerce").fillna(0).round(0).astype(int)
    weeks = pd.to_datetime(df["Week"], errors="coerce").dt.date
    part  = (df["isPartial"].astype(str).str.lower().map({"true":True,"false":False}).fillna(False)
             if "isPartial" in df.columns else pd.Series([False]*len(df)))

    # limit to the target year
    mask = (weeks >= pd.to_datetime(f"{YEAR}-01-01").date()) & (weeks <= pd.to_datetime(f"{YEAR}-12-31").date())
    weeks, vals, part = weeks[mask], vals[mask], part[mask]

    if len(weeks) == 0:
        return pd.DataFrame()

    series_max = int(vals.max())
    has_100 = 1 if series_max == 100 else 0
    keep = vals >= THRESHOLD
    if keep.sum() == 0:
        return pd.DataFrame()

    return pd.DataFrame({
        "ticker": ticker,
        "week_start": weeks[keep].astype(str).values,
        "gst_value": vals[keep].astype(int).values,
        "is_partial": ["yes" if b else "no" for b in part[keep].astype(bool).values],
        "csv_file": csv_path.name,
        "value_column_used": val_col,
        "series_max": series_max,
        "has_100": has_100,
        "year": YEAR
    })

def main():
    OUTFILE.parent.mkdir(parents=True, exist_ok=True)
    rows = []

    for tkr in TICKERS:
        csv_path = CSV_DIR / f"{tkr}.csv"
        df = read_one(csv_path, tkr)
        if not df.empty:
            rows.append(df)

    if not rows:
        pd.DataFrame(columns=[
            "ticker","week_start","gst_value","is_partial","csv_file",
            "value_column_used","series_max","has_100","year"
        ]).to_csv(OUTFILE, index=False, encoding="utf-8")
        print(f"No peaks >= {THRESHOLD}; wrote header-only file to {OUTFILE}")
        return

    out = pd.concat(rows, ignore_index=True)
    out.to_csv(OUTFILE, index=False, encoding="utf-8")
    print(f"Wrote {len(out)} rows to {OUTFILE}")

if __name__ == "__main__":
    main()
